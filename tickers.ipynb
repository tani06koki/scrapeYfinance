{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape ticker lists from Yahoo Finance Screeners by BeautifulSoup\n",
    "URL: https://finance.yahoo.com/screener/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a todays date folde under \"data\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data\\\\20112024'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get today's date in the format \"ddmmyyyy\"\n",
    "today_date = datetime.now().strftime(\"%d%m%Y\")\n",
    "\n",
    "# Define the path for the new folder\n",
    "folder_path = os.path.join(\"data\", today_date)\n",
    "\n",
    "# Create the folder\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Confirm the folder creation\n",
    "folder_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Screeners URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aggressive_small_caps = \"https://finance.yahoo.com/screener/predefined/aggressive_small_caps/\"\n",
    "Conservative_foreign_funds = \"https://finance.yahoo.com/screener/predefined/conservative_foreign_funds/\"\n",
    "Day_gainers = \"https://finance.yahoo.com/screener/predefined/day_gainers/\"\n",
    "Day_losers = \"https://finance.yahoo.com/screener/predefined/day_losers/\"\n",
    "Growth_technology_stocks = \"https://finance.yahoo.com/screener/predefined/growth_technology_stocks/\"\n",
    "High_yield_bond = \"https://finance.yahoo.com/screener/predefined/high_yield_bond/\"\n",
    "Most_actives = \"https://finance.yahoo.com/screener/predefined/most_actives/\"\n",
    "Most_shorted_stocks = \"https://finance.yahoo.com/screener/predefined/most_shorted_stocks/\"\n",
    "Portfolio_anchors = \"https://finance.yahoo.com/screener/predefined/portfolio_anchors/\"\n",
    "Small_cap_gainers = \"https://finance.yahoo.com/screener/predefined/small_cap_gainers/\"\n",
    "Solid_large_growth_funds = \"https://finance.yahoo.com/screener/predefined/solid_large_growth_funds/\"\n",
    "Solid_midcap_growth_funds = \"https://finance.yahoo.com/screener/predefined/solid_midcap_growth_funds/\"\n",
    "Top_mutual_funds = \"https://finance.yahoo.com/screener/predefined/top_mutual_funds/\"\n",
    "Undervalued_growth_stocks = \"https://finance.yahoo.com/screener/predefined/undervalued_growth_stocks/\"\n",
    "Undervalued_large_caps = \"https://finance.yahoo.com/screener/predefined/undervalued_large_caps/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape tickers from each screener"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggressive Small Caps\n",
    "#### Stocks\n",
    "Small cap stocks with high earnings growth rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://finance.yahoo.com/screener/predefined/aggressive_small_caps/?count=25&offset=0\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/aggressive_small_caps/?count=25&offset=25\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/aggressive_small_caps/?count=25&offset=50\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/aggressive_small_caps/?count=25&offset=75\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/aggressive_small_caps/?count=25&offset=100\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/aggressive_small_caps/?count=25&offset=125\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/aggressive_small_caps/?count=25&offset=150\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/aggressive_small_caps/?count=25&offset=175\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/aggressive_small_caps/?count=25&offset=200\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/aggressive_small_caps/?count=25&offset=225\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/aggressive_small_caps/?count=25&offset=250\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/aggressive_small_caps/?count=25&offset=275\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/aggressive_small_caps/?count=25&offset=300\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/aggressive_small_caps/?count=25&offset=325\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/aggressive_small_caps/?count=25&offset=350\n",
      "Total Tickers Extracted: 334\n",
      "Data saved to: data\\20112024\\Aggressive_small_caps_tickers.csv\n",
      "Total Tickers Extracted: 334\n",
      "Data saved to: tickers\\Aggressive_small_caps_tickers.csv\n"
     ]
    }
   ],
   "source": [
    "# Headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "count = 25  # count per page\n",
    "offset = 0  # initial offset\n",
    "all_tickers = []  # list to store all tickers\n",
    "\n",
    "while True:\n",
    "    # Define URL\n",
    "    url = f\"{Aggressive_small_caps}?count={count}&offset={offset}\"\n",
    "    print(f\"Fetching: {url}\")\n",
    "    \n",
    "    # Request the page\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # get tickers\n",
    "    tickers = [tag.text.strip() for tag in soup.find_all('a', {'data-test': 'quoteLink'})]\n",
    "    \n",
    "    # terminate if there is no more tickers\n",
    "    if not tickers:\n",
    "        break\n",
    "    \n",
    "    # add tickers to a list\n",
    "    all_tickers.extend(tickers)\n",
    "    \n",
    "    # increase the offset\n",
    "    offset += count\n",
    "\n",
    "# Save data to a CSV file in the newly created folder\n",
    "df = pd.DataFrame(all_tickers, columns=[\"Ticker\"])\n",
    "csv_file_path = os.path.join(folder_path, \"Aggressive_small_caps_tickers.csv\")\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {csv_file_path}\")\n",
    "\n",
    "# Save to 'tickers\" as the latest tickers\n",
    "latest_path = os.path.join('tickers', \"Aggressive_small_caps_tickers.csv\")\n",
    "df.to_csv(latest_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {latest_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conservative Foreign Funds\n",
    "#### Mutual Funds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://finance.yahoo.com/screener/predefined/conservative_foreign_funds/?count=25&offset=0\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/conservative_foreign_funds/?count=25&offset=25\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/conservative_foreign_funds/?count=25&offset=50\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/conservative_foreign_funds/?count=25&offset=75\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/conservative_foreign_funds/?count=25&offset=100\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/conservative_foreign_funds/?count=25&offset=125\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/conservative_foreign_funds/?count=25&offset=150\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/conservative_foreign_funds/?count=25&offset=175\n",
      "Total Tickers Extracted: 161\n",
      "Data saved to: data\\20112024\\Conservative_foreign_funds.csv\n",
      "Total Tickers Extracted: 161\n",
      "Data saved to: tickers\\Conservative_foreign_funds.csv\n"
     ]
    }
   ],
   "source": [
    "# Headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "count = 25  # count per page\n",
    "offset = 0  # initial offset\n",
    "all_tickers = []  # list to store all tickers\n",
    "\n",
    "while True:\n",
    "    # Define URL\n",
    "    url = f\"{Conservative_foreign_funds}?count={count}&offset={offset}\"\n",
    "    print(f\"Fetching: {url}\")\n",
    "    \n",
    "    # Request the page\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # get tickers\n",
    "    tickers = [tag.text.strip() for tag in soup.find_all('a', {'data-test': 'quoteLink'})]\n",
    "    \n",
    "    # terminate if there is no more tickers\n",
    "    if not tickers:\n",
    "        break\n",
    "    \n",
    "    # add tickers to a list\n",
    "    all_tickers.extend(tickers)\n",
    "    \n",
    "    # increase the offset\n",
    "    offset += count\n",
    "\n",
    "# Save data to a CSV file in the newly created folder\n",
    "df = pd.DataFrame(all_tickers, columns=[\"Ticker\"])\n",
    "csv_file_path = os.path.join(folder_path, \"Conservative_foreign_funds.csv\")\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {csv_file_path}\")\n",
    "\n",
    "# Save to 'tickers\" as the latest tickers\n",
    "latest_path = os.path.join('tickers', \"Conservative_foreign_funds.csv\")\n",
    "df.to_csv(latest_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {latest_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day_gainers\n",
    "#### Stocks\n",
    "Discover the equities with the greatest gains in the trading day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://finance.yahoo.com/screener/predefined/day_gainers/?count=25&offset=0\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/day_gainers/?count=25&offset=25\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/day_gainers/?count=25&offset=50\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/day_gainers/?count=25&offset=75\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/day_gainers/?count=25&offset=100\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/day_gainers/?count=25&offset=125\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/day_gainers/?count=25&offset=150\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/day_gainers/?count=25&offset=175\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/day_gainers/?count=25&offset=200\n",
      "Total Tickers Extracted: 176\n",
      "Data saved to: data\\20112024\\Day_gainers.csv\n",
      "Total Tickers Extracted: 176\n",
      "Data saved to: tickers\\Day_gainers.csv\n"
     ]
    }
   ],
   "source": [
    "# Headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "count = 25  # count per page\n",
    "offset = 0  # initial offset\n",
    "all_tickers = []  # list to store all tickers\n",
    "\n",
    "while True:\n",
    "    # Define URL\n",
    "    url = f\"{Day_gainers}?count={count}&offset={offset}\"\n",
    "    print(f\"Fetching: {url}\")\n",
    "    \n",
    "    # Request the page\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # get tickers\n",
    "    tickers = [tag.text.strip() for tag in soup.find_all('a', {'data-test': 'quoteLink'})]\n",
    "    \n",
    "    # terminate if there is no more tickers\n",
    "    if not tickers:\n",
    "        break\n",
    "    \n",
    "    # add tickers to a list\n",
    "    all_tickers.extend(tickers)\n",
    "    \n",
    "    # increase the offset\n",
    "    offset += count\n",
    "\n",
    "# Save data to a CSV file in the newly created folder\n",
    "df = pd.DataFrame(all_tickers, columns=[\"Ticker\"])\n",
    "csv_file_path = os.path.join(folder_path, \"Day_gainers.csv\")\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {csv_file_path}\")\n",
    "\n",
    "# Save to 'tickers\" as the latest tickers\n",
    "latest_path = os.path.join('tickers', \"Day_gainers.csv\")\n",
    "df.to_csv(latest_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {latest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day_losers\n",
    "#### Stocks\n",
    "Discover the equities with the greatest losses in the trading day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://finance.yahoo.com/screener/predefined/day_losers/?count=25&offset=0\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/day_losers/?count=25&offset=25\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/day_losers/?count=25&offset=50\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/day_losers/?count=25&offset=75\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/day_losers/?count=25&offset=100\n",
      "Total Tickers Extracted: 89\n",
      "Data saved to: data\\20112024\\Day_losers.csv\n",
      "Total Tickers Extracted: 89\n",
      "Data saved to: tickers\\Day_losers.csv\n"
     ]
    }
   ],
   "source": [
    "# Headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "count = 25  # count per page\n",
    "offset = 0  # initial offset\n",
    "all_tickers = []  # list to store all tickers\n",
    "\n",
    "while True:\n",
    "    # Define URL\n",
    "    url = f\"{Day_losers}?count={count}&offset={offset}\"\n",
    "    print(f\"Fetching: {url}\")\n",
    "    \n",
    "    # Request the page\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # get tickers\n",
    "    tickers = [tag.text.strip() for tag in soup.find_all('a', {'data-test': 'quoteLink'})]\n",
    "    \n",
    "    # terminate if there is no more tickers\n",
    "    if not tickers:\n",
    "        break\n",
    "    \n",
    "    # add tickers to a list\n",
    "    all_tickers.extend(tickers)\n",
    "    \n",
    "    # increase the offset\n",
    "    offset += count\n",
    "\n",
    "# Save data to a CSV file in the newly created folder\n",
    "df = pd.DataFrame(all_tickers, columns=[\"Ticker\"])\n",
    "csv_file_path = os.path.join(folder_path, \"Day_losers.csv\")\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {csv_file_path}\")\n",
    "\n",
    "# Save to 'tickers\" as the latest tickers\n",
    "latest_path = os.path.join('tickers', \"Day_losers.csv\")\n",
    "df.to_csv(latest_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {latest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Growth Technology Stocks\n",
    "#### Stocks\n",
    "Technology stocks with revenue and earnings growth in excess of 25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://finance.yahoo.com/screener/predefined/growth_technology_stocks/?count=25&offset=0\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/growth_technology_stocks/?count=25&offset=25\n",
      "Total Tickers Extracted: 16\n",
      "Data saved to: data\\20112024\\Growth_technology_stocks.csv\n",
      "Total Tickers Extracted: 16\n",
      "Data saved to: tickers\\Growth_technology_stocks.csv\n"
     ]
    }
   ],
   "source": [
    "# Headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "count = 25  # count per page\n",
    "offset = 0  # initial offset\n",
    "all_tickers = []  # list to store all tickers\n",
    "\n",
    "while True:\n",
    "    # Define URL\n",
    "    url = f\"{Growth_technology_stocks}?count={count}&offset={offset}\"\n",
    "    print(f\"Fetching: {url}\")\n",
    "    \n",
    "    # Request the page\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # get tickers\n",
    "    tickers = [tag.text.strip() for tag in soup.find_all('a', {'data-test': 'quoteLink'})]\n",
    "    \n",
    "    # terminate if there is no more tickers\n",
    "    if not tickers:\n",
    "        break\n",
    "    \n",
    "    # add tickers to a list\n",
    "    all_tickers.extend(tickers)\n",
    "    \n",
    "    # increase the offset\n",
    "    offset += count\n",
    "\n",
    "# Save data to a CSV file in the newly created folder\n",
    "df = pd.DataFrame(all_tickers, columns=[\"Ticker\"])\n",
    "csv_file_path = os.path.join(folder_path, \"Growth_technology_stocks.csv\")\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {csv_file_path}\")\n",
    "\n",
    "# Save to 'tickers\" as the latest tickers\n",
    "latest_path = os.path.join('tickers', \"Growth_technology_stocks.csv\")\n",
    "df.to_csv(latest_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {latest_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\20112024\n"
     ]
    }
   ],
   "source": [
    "print(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Yield Bond\n",
    "#### Mutual Funds\n",
    "High Yield Bond with Performance Rating of 4 & 5, low risk and top-half returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://finance.yahoo.com/screener/predefined/high_yield_bond/?count=25&offset=0\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/high_yield_bond/?count=25&offset=25\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/high_yield_bond/?count=25&offset=50\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/high_yield_bond/?count=25&offset=75\n",
      "Total Tickers Extracted: 72\n",
      "Data saved to: data\\20112024\\High_yield_bond.csv\n",
      "Total Tickers Extracted: 72\n",
      "Data saved to: tickers\\High_yield_bond.csv\n"
     ]
    }
   ],
   "source": [
    "# Headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "count = 25  # count per page\n",
    "offset = 0  # initial offset\n",
    "all_tickers = []  # list to store all tickers\n",
    "\n",
    "while True:\n",
    "    # Define URL\n",
    "    url = f\"{High_yield_bond}?count={count}&offset={offset}\"\n",
    "    print(f\"Fetching: {url}\")\n",
    "    \n",
    "    # Request the page\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # get tickers\n",
    "    tickers = [tag.text.strip() for tag in soup.find_all('a', {'data-test': 'quoteLink'})]\n",
    "    \n",
    "    # terminate if there is no more tickers\n",
    "    if not tickers:\n",
    "        break\n",
    "    \n",
    "    # add tickers to a list\n",
    "    all_tickers.extend(tickers)\n",
    "    \n",
    "    # increase the offset\n",
    "    offset += count\n",
    "\n",
    "# Save data to a CSV file in the newly created folder\n",
    "df = pd.DataFrame(all_tickers, columns=[\"Ticker\"])\n",
    "csv_file_path = os.path.join(folder_path, \"High_yield_bond.csv\")\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {csv_file_path}\")\n",
    "\n",
    "# Save to 'tickers\" as the latest tickers\n",
    "latest_path = os.path.join('tickers', \"High_yield_bond.csv\")\n",
    "df.to_csv(latest_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {latest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Actives\n",
    "#### Stocks\n",
    "Discover the most traded equities in the trading day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://finance.yahoo.com/screener/predefined/most_actives/?count=25&offset=0\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/most_actives/?count=25&offset=25\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/most_actives/?count=25&offset=50\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/most_actives/?count=25&offset=75\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/most_actives/?count=25&offset=100\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/most_actives/?count=25&offset=125\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/most_actives/?count=25&offset=150\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/most_actives/?count=25&offset=175\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/most_actives/?count=25&offset=200\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/most_actives/?count=25&offset=225\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/most_actives/?count=25&offset=250\n",
      "Total Tickers Extracted: 231\n",
      "Data saved to: data\\20112024\\Matching_mutual_funds.csv\n",
      "Total Tickers Extracted: 231\n",
      "Data saved to: tickers\\Matching_mutual_funds.csv\n"
     ]
    }
   ],
   "source": [
    "# Headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "count = 25  # count per page\n",
    "offset = 0  # initial offset\n",
    "all_tickers = []  # list to store all tickers\n",
    "\n",
    "while True:\n",
    "    # Define URL\n",
    "    url = f\"{Most_actives}?count={count}&offset={offset}\"\n",
    "    print(f\"Fetching: {url}\")\n",
    "    \n",
    "    # Request the page\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # get tickers\n",
    "    tickers = [tag.text.strip() for tag in soup.find_all('a', {'data-test': 'quoteLink'})]\n",
    "    \n",
    "    # terminate if there is no more tickers\n",
    "    if not tickers:\n",
    "        break\n",
    "    \n",
    "    # add tickers to a list\n",
    "    all_tickers.extend(tickers)\n",
    "    \n",
    "    # increase the offset\n",
    "    offset += count\n",
    "\n",
    "# Save data to a CSV file in the newly created folder\n",
    "df = pd.DataFrame(all_tickers, columns=[\"Ticker\"])\n",
    "csv_file_path = os.path.join(folder_path, \"Matching_mutual_funds.csv\")\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {csv_file_path}\")\n",
    "\n",
    "# Save to 'tickers\" as the latest tickers\n",
    "latest_path = os.path.join('tickers', \"Matching_mutual_funds.csv\")\n",
    "df.to_csv(latest_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {latest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Shorted Stocks\n",
    "#### Stocks\n",
    "Stocks with the highest short interest positions from Nasdaq and NYSE reports released every two weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://finance.yahoo.com/screener/predefined/conservative_foreign_funds/?count=25&offset=0\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/conservative_foreign_funds/?count=25&offset=25\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/conservative_foreign_funds/?count=25&offset=50\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/conservative_foreign_funds/?count=25&offset=75\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/conservative_foreign_funds/?count=25&offset=100\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/conservative_foreign_funds/?count=25&offset=125\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/conservative_foreign_funds/?count=25&offset=150\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/conservative_foreign_funds/?count=25&offset=175\n",
      "Total Tickers Extracted: 161\n",
      "Data saved to: data\\20112024\\Most_actives.csv\n",
      "Total Tickers Extracted: 161\n",
      "Data saved to: tickers\\Most_actives.csv\n"
     ]
    }
   ],
   "source": [
    "# Headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "count = 25  # count per page\n",
    "offset = 0  # initial offset\n",
    "all_tickers = []  # list to store all tickers\n",
    "\n",
    "while True:\n",
    "    # Define URL\n",
    "    url = f\"{Matching_mutual_funds}?count={count}&offset={offset}\"\n",
    "    print(f\"Fetching: {url}\")\n",
    "    \n",
    "    # Request the page\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # get tickers\n",
    "    tickers = [tag.text.strip() for tag in soup.find_all('a', {'data-test': 'quoteLink'})]\n",
    "    \n",
    "    # terminate if there is no more tickers\n",
    "    if not tickers:\n",
    "        break\n",
    "    \n",
    "    # add tickers to a list\n",
    "    all_tickers.extend(tickers)\n",
    "    \n",
    "    # increase the offset\n",
    "    offset += count\n",
    "\n",
    "# Save data to a CSV file in the newly created folder\n",
    "df = pd.DataFrame(all_tickers, columns=[\"Ticker\"])\n",
    "csv_file_path = os.path.join(folder_path, \"Most_actives.csv\")\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {csv_file_path}\")\n",
    "\n",
    "# Save to 'tickers\" as the latest tickers\n",
    "latest_path = os.path.join('tickers', \"Most_actives.csv\")\n",
    "df.to_csv(latest_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {latest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portfolio Anchors\n",
    "#### Mutual Funds\n",
    "Funds with Performance Rating of 4 & 5 and top-half returns that could serve as a rock-solid core of an investor's portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://finance.yahoo.com/screener/predefined/portfolio_anchors/?count=25&offset=0\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/portfolio_anchors/?count=25&offset=25\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/portfolio_anchors/?count=25&offset=50\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/portfolio_anchors/?count=25&offset=75\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/portfolio_anchors/?count=25&offset=100\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/portfolio_anchors/?count=25&offset=125\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/portfolio_anchors/?count=25&offset=150\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/portfolio_anchors/?count=25&offset=175\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/portfolio_anchors/?count=25&offset=200\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/portfolio_anchors/?count=25&offset=225\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/portfolio_anchors/?count=25&offset=250\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/portfolio_anchors/?count=25&offset=275\n",
      "Total Tickers Extracted: 270\n",
      "Data saved to: data\\20112024\\Portfolio_anchors.csv\n",
      "Total Tickers Extracted: 270\n",
      "Data saved to: tickers\\Portfolio_anchors.csv\n"
     ]
    }
   ],
   "source": [
    "# Headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "count = 25  # count per page\n",
    "offset = 0  # initial offset\n",
    "all_tickers = []  # list to store all tickers\n",
    "\n",
    "while True:\n",
    "    # Define URL\n",
    "    url = f\"{Portfolio_anchors}?count={count}&offset={offset}\"\n",
    "    print(f\"Fetching: {url}\")\n",
    "    \n",
    "    # Request the page\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # get tickers\n",
    "    tickers = [tag.text.strip() for tag in soup.find_all('a', {'data-test': 'quoteLink'})]\n",
    "    \n",
    "    # terminate if there is no more tickers\n",
    "    if not tickers:\n",
    "        break\n",
    "    \n",
    "    # add tickers to a list\n",
    "    all_tickers.extend(tickers)\n",
    "    \n",
    "    # increase the offset\n",
    "    offset += count\n",
    "\n",
    "# Save data to a CSV file in the newly created folder\n",
    "df = pd.DataFrame(all_tickers, columns=[\"Ticker\"])\n",
    "csv_file_path = os.path.join(folder_path, \"Portfolio_anchors.csv\")\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {csv_file_path}\")\n",
    "\n",
    "# Save to 'tickers\" as the latest tickers\n",
    "latest_path = os.path.join('tickers', \"Portfolio_anchors.csv\")\n",
    "df.to_csv(latest_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {latest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small Cap Gainers\n",
    "#### Stocks\n",
    "Small cap stocks with percentchange greater than 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://finance.yahoo.com/screener/predefined/small_cap_gainers/?count=25&offset=0\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/small_cap_gainers/?count=25&offset=25\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/small_cap_gainers/?count=25&offset=50\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/small_cap_gainers/?count=25&offset=75\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/small_cap_gainers/?count=25&offset=100\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/small_cap_gainers/?count=25&offset=125\n",
      "Total Tickers Extracted: 106\n",
      "Data saved to: data\\20112024\\Small_cap_gainers.csv\n",
      "Total Tickers Extracted: 106\n",
      "Data saved to: tickers\\Small_cap_gainers.csv\n"
     ]
    }
   ],
   "source": [
    "# Headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "count = 25  # count per page\n",
    "offset = 0  # initial offset\n",
    "all_tickers = []  # list to store all tickers\n",
    "\n",
    "while True:\n",
    "    # Define URL\n",
    "    url = f\"{Small_cap_gainers}?count={count}&offset={offset}\"\n",
    "    print(f\"Fetching: {url}\")\n",
    "    \n",
    "    # Request the page\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # get tickers\n",
    "    tickers = [tag.text.strip() for tag in soup.find_all('a', {'data-test': 'quoteLink'})]\n",
    "    \n",
    "    # terminate if there is no more tickers\n",
    "    if not tickers:\n",
    "        break\n",
    "    \n",
    "    # add tickers to a list\n",
    "    all_tickers.extend(tickers)\n",
    "    \n",
    "    # increase the offset\n",
    "    offset += count\n",
    "\n",
    "# Save data to a CSV file in the newly created folder\n",
    "df = pd.DataFrame(all_tickers, columns=[\"Ticker\"])\n",
    "csv_file_path = os.path.join(folder_path, \"Small_cap_gainers.csv\")\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {csv_file_path}\")\n",
    "\n",
    "# Save to 'tickers\" as the latest tickers\n",
    "latest_path = os.path.join('tickers', \"Small_cap_gainers.csv\")\n",
    "df.to_csv(latest_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {latest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solid Large Growth Funds\n",
    "#### Mutual Funds\n",
    "Large Growth Funds with Performance Rating of 4 & 5 and top-half returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://finance.yahoo.com/screener/predefined/solid_large_growth_funds/?count=25&offset=0\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/solid_large_growth_funds/?count=25&offset=25\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/solid_large_growth_funds/?count=25&offset=50\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/solid_large_growth_funds/?count=25&offset=75\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/solid_large_growth_funds/?count=25&offset=100\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/solid_large_growth_funds/?count=25&offset=125\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/solid_large_growth_funds/?count=25&offset=150\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/solid_large_growth_funds/?count=25&offset=175\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/solid_large_growth_funds/?count=25&offset=200\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/solid_large_growth_funds/?count=25&offset=225\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/solid_large_growth_funds/?count=25&offset=250\n",
      "Total Tickers Extracted: 228\n",
      "Data saved to: data\\20112024\\Solid_large_growth_funds.csv\n",
      "Total Tickers Extracted: 228\n",
      "Data saved to: tickers\\Solid_large_growth_funds.csv\n"
     ]
    }
   ],
   "source": [
    "# Headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "count = 25  # count per page\n",
    "offset = 0  # initial offset\n",
    "all_tickers = []  # list to store all tickers\n",
    "\n",
    "while True:\n",
    "    # Define URL\n",
    "    url = f\"{Solid_large_growth_funds}?count={count}&offset={offset}\"\n",
    "    print(f\"Fetching: {url}\")\n",
    "    \n",
    "    # Request the page\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # get tickers\n",
    "    tickers = [tag.text.strip() for tag in soup.find_all('a', {'data-test': 'quoteLink'})]\n",
    "    \n",
    "    # terminate if there is no more tickers\n",
    "    if not tickers:\n",
    "        break\n",
    "    \n",
    "    # add tickers to a list\n",
    "    all_tickers.extend(tickers)\n",
    "    \n",
    "    # increase the offset\n",
    "    offset += count\n",
    "\n",
    "# Save data to a CSV file in the newly created folder\n",
    "df = pd.DataFrame(all_tickers, columns=[\"Ticker\"])\n",
    "csv_file_path = os.path.join(folder_path, \"Solid_large_growth_funds.csv\")\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {csv_file_path}\")\n",
    "\n",
    "# Save to 'tickers\" as the latest tickers\n",
    "latest_path = os.path.join('tickers', \"Solid_large_growth_funds.csv\")\n",
    "df.to_csv(latest_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {latest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solid Midcap Growth Funds\n",
    "#### Mutual Funds\n",
    "Mid-Cap Growth Funds with Performance Rating of 4 & 5 and top-half returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://finance.yahoo.com/screener/predefined/solid_midcap_growth_funds/?count=25&offset=0\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/solid_midcap_growth_funds/?count=25&offset=25\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/solid_midcap_growth_funds/?count=25&offset=50\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/solid_midcap_growth_funds/?count=25&offset=75\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/solid_midcap_growth_funds/?count=25&offset=100\n",
      "Total Tickers Extracted: 85\n",
      "Data saved to: data\\20112024\\Solid_midcap_growth_funds.csv\n",
      "Total Tickers Extracted: 85\n",
      "Data saved to: tickers\\Solid_midcap_growth_funds.csv\n"
     ]
    }
   ],
   "source": [
    "# Headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "count = 25  # count per page\n",
    "offset = 0  # initial offset\n",
    "all_tickers = []  # list to store all tickers\n",
    "\n",
    "while True:\n",
    "    # Define URL\n",
    "    url = f\"{Solid_midcap_growth_funds}?count={count}&offset={offset}\"\n",
    "    print(f\"Fetching: {url}\")\n",
    "    \n",
    "    # Request the page\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # get tickers\n",
    "    tickers = [tag.text.strip() for tag in soup.find_all('a', {'data-test': 'quoteLink'})]\n",
    "    \n",
    "    # terminate if there is no more tickers\n",
    "    if not tickers:\n",
    "        break\n",
    "    \n",
    "    # add tickers to a list\n",
    "    all_tickers.extend(tickers)\n",
    "    \n",
    "    # increase the offset\n",
    "    offset += count\n",
    "\n",
    "# Save data to a CSV file in the newly created folder\n",
    "df = pd.DataFrame(all_tickers, columns=[\"Ticker\"])\n",
    "csv_file_path = os.path.join(folder_path, \"Solid_midcap_growth_funds.csv\")\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {csv_file_path}\")\n",
    "\n",
    "# Save to 'tickers\" as the latest tickers\n",
    "latest_path = os.path.join('tickers', \"Solid_midcap_growth_funds.csv\")\n",
    "df.to_csv(latest_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {latest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Mutual Funds\n",
    "#### Mutual Funds\n",
    "Funds with Performance Rating of 4 & 5 ordered by Percent Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=0\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=25\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=50\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=75\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=100\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=125\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=150\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=175\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=200\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=225\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=250\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=275\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=300\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=325\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=350\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=375\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=400\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=425\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=450\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=475\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=500\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=525\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=550\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=575\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=600\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=625\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=650\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=675\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=700\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=725\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=750\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=775\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=800\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=825\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=850\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=875\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=900\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=925\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=950\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=975\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1000\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1025\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1050\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1075\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1100\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1125\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1150\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1175\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1200\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1225\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1250\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1275\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1300\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1325\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1350\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1375\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1400\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1425\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1450\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1475\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1500\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1525\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1550\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1575\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1600\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1625\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1650\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1675\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1700\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1725\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1750\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1775\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/top_mutual_funds/?count=25&offset=1800\n",
      "Total Tickers Extracted: 1796\n",
      "Data saved to: data\\20112024\\Top_mutual_funds.csv\n",
      "Total Tickers Extracted: 1796\n",
      "Data saved to: tickers\\Top_mutual_funds.csv\n"
     ]
    }
   ],
   "source": [
    "# Headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "count = 25  # count per page\n",
    "offset = 0  # initial offset\n",
    "all_tickers = []  # list to store all tickers\n",
    "\n",
    "while True:\n",
    "    # Define URL\n",
    "    url = f\"{Top_mutual_funds}?count={count}&offset={offset}\"\n",
    "    print(f\"Fetching: {url}\")\n",
    "    \n",
    "    # Request the page\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # get tickers\n",
    "    tickers = [tag.text.strip() for tag in soup.find_all('a', {'data-test': 'quoteLink'})]\n",
    "    \n",
    "    # terminate if there is no more tickers\n",
    "    if not tickers:\n",
    "        break\n",
    "    \n",
    "    # add tickers to a list\n",
    "    all_tickers.extend(tickers)\n",
    "    \n",
    "    # increase the offset\n",
    "    offset += count\n",
    "\n",
    "# Save data to a CSV file in the newly created folder\n",
    "df = pd.DataFrame(all_tickers, columns=[\"Ticker\"])\n",
    "csv_file_path = os.path.join(folder_path, \"Top_mutual_funds.csv\")\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {csv_file_path}\")\n",
    "\n",
    "# Save to 'tickers\" as the latest tickers\n",
    "latest_path = os.path.join('tickers', \"Top_mutual_funds.csv\")\n",
    "df.to_csv(latest_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {latest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undervalued Growth Stocks\n",
    "#### Stocks\n",
    "Stocks with earnings growth rates better than 25% and relatively low PE and PEG ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://finance.yahoo.com/screener/predefined/undervalued_growth_stocks/?count=25&offset=0\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/undervalued_growth_stocks/?count=25&offset=25\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/undervalued_growth_stocks/?count=25&offset=50\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/undervalued_growth_stocks/?count=25&offset=75\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/undervalued_growth_stocks/?count=25&offset=100\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/undervalued_growth_stocks/?count=25&offset=125\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/undervalued_growth_stocks/?count=25&offset=150\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/undervalued_growth_stocks/?count=25&offset=175\n",
      "Total Tickers Extracted: 164\n",
      "Data saved to: data\\20112024\\Undervalued_growth_stocks.csv\n",
      "Total Tickers Extracted: 164\n",
      "Data saved to: tickers\\Undervalued_growth_stocks.csv\n"
     ]
    }
   ],
   "source": [
    "# Headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "count = 25  # count per page\n",
    "offset = 0  # initial offset\n",
    "all_tickers = []  # list to store all tickers\n",
    "\n",
    "while True:\n",
    "    # Define URL\n",
    "    url = f\"{Undervalued_growth_stocks}?count={count}&offset={offset}\"\n",
    "    print(f\"Fetching: {url}\")\n",
    "    \n",
    "    # Request the page\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # get tickers\n",
    "    tickers = [tag.text.strip() for tag in soup.find_all('a', {'data-test': 'quoteLink'})]\n",
    "    \n",
    "    # terminate if there is no more tickers\n",
    "    if not tickers:\n",
    "        break\n",
    "    \n",
    "    # add tickers to a list\n",
    "    all_tickers.extend(tickers)\n",
    "    \n",
    "    # increase the offset\n",
    "    offset += count\n",
    "\n",
    "# Save data to a CSV file in the newly created folder\n",
    "df = pd.DataFrame(all_tickers, columns=[\"Ticker\"])\n",
    "csv_file_path = os.path.join(folder_path, \"Undervalued_growth_stocks.csv\")\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {csv_file_path}\")\n",
    "\n",
    "# Save to 'tickers\" as the latest tickers\n",
    "latest_path = os.path.join('tickers', \"Undervalued_growth_stocks.csv\")\n",
    "df.to_csv(latest_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {latest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undervalued Large Caps\n",
    "#### Stocks\n",
    "Large cap stocks that are potentially undervalued, ordered descending by volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: https://finance.yahoo.com/screener/predefined/undervalued_large_caps/?count=25&offset=0\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/undervalued_large_caps/?count=25&offset=25\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/undervalued_large_caps/?count=25&offset=50\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/undervalued_large_caps/?count=25&offset=75\n",
      "Fetching: https://finance.yahoo.com/screener/predefined/undervalued_large_caps/?count=25&offset=100\n",
      "Total Tickers Extracted: 95\n",
      "Data saved to: data\\20112024\\Undervalued_large_caps.csv\n",
      "Total Tickers Extracted: 95\n",
      "Data saved to: tickers\\Undervalued_large_caps.csv\n"
     ]
    }
   ],
   "source": [
    "# Headers\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "count = 25  # count per page\n",
    "offset = 0  # initial offset\n",
    "all_tickers = []  # list to store all tickers\n",
    "\n",
    "while True:\n",
    "    # Define URL\n",
    "    url = f\"{Undervalued_large_caps}?count={count}&offset={offset}\"\n",
    "    print(f\"Fetching: {url}\")\n",
    "    \n",
    "    # Request the page\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # get tickers\n",
    "    tickers = [tag.text.strip() for tag in soup.find_all('a', {'data-test': 'quoteLink'})]\n",
    "    \n",
    "    # terminate if there is no more tickers\n",
    "    if not tickers:\n",
    "        break\n",
    "    \n",
    "    # add tickers to a list\n",
    "    all_tickers.extend(tickers)\n",
    "    \n",
    "    # increase the offset\n",
    "    offset += count\n",
    "\n",
    "# Save data to a CSV file in the newly created folder\n",
    "df = pd.DataFrame(all_tickers, columns=[\"Ticker\"])\n",
    "csv_file_path = os.path.join(folder_path, \"Undervalued_large_caps.csv\")\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {csv_file_path}\")\n",
    "\n",
    "# Save to 'tickers\" as the latest tickers\n",
    "latest_path = os.path.join('tickers', \"Undervalued_large_caps.csv\")\n",
    "df.to_csv(latest_path, index=False)\n",
    "\n",
    "print(f\"Total Tickers Extracted: {len(all_tickers)}\")\n",
    "print(f\"Data saved to: {latest_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
